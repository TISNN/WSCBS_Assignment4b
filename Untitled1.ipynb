{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9226747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ed602861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b17e986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Embarked[train_data.Embarked.isnull()] = train_data.Embarked.dropna().mode().values\n",
    "#replace missing value with U0\n",
    "train_data['Cabin'] = train_data.Cabin.fillna('U0')    \n",
    "#train_data.Cabin[train_data.CAbin.isnull()]='U0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7989fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#choose training data to predict age\n",
    "age_df = train_data[['Age','Survived','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "age_df_notnull = age_df.loc[(train_data['Age'].notnull())]\n",
    "age_df_isnull = age_df.loc[(train_data['Age'].isnull())]\n",
    "X = age_df_notnull.values[:,1:]\n",
    "Y = age_df_notnull.values[:,0]\n",
    "\n",
    "# use RandomForestRegression to train data\n",
    "RFR = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "RFR.fit(X,Y)\n",
    "predictAges = RFR.predict(age_df_isnull.values[:,1:])\n",
    "train_data.loc[train_data['Age'].isnull(), ['Age']]= predictAges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5b2dc5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male\n",
       "Title                 \n",
       "Capt           0     1\n",
       "Col            0     2\n",
       "Countess       1     0\n",
       "Don            0     1\n",
       "Dr             1     6\n",
       "Jonkheer       0     1\n",
       "Lady           1     0\n",
       "Major          0     2\n",
       "Master         0    40\n",
       "Miss         182     0\n",
       "Mlle           2     0\n",
       "Mme            1     0\n",
       "Mr             0   517\n",
       "Mrs          125     0\n",
       "Ms             1     0\n",
       "Rev            0     6\n",
       "Sir            0     1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "pd.crosstab(train_data['Title'],train_data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1e0d807c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S  C  Q\n",
       "0  1  0  0\n",
       "1  0  1  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embark_dummies = pd.get_dummies(train_data['Embarked'])\n",
    "train_data = train_data.join(embark_dummies)\n",
    "train_data.drop(['Embarked'], axis=1, inplace=True)\n",
    "\n",
    "embark_dummies = train_data[['S','C','Q']]\n",
    "embark_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "83835f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    " \n",
    "assert np.size(train_data['Age']) == 891\n",
    "# StandardScaler will subtract the mean from each value then scale to the unit varience\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train_data['Age_scaled'] = scaler.fit_transform(train_data['Age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f6428dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      (-0.001, 7.854]\n",
      "1    (39.688, 512.329]\n",
      "2        (7.854, 10.5]\n",
      "3    (39.688, 512.329]\n",
      "4        (7.854, 10.5]\n",
      "Name: Fare_bin, dtype: category\n",
      "Categories (5, interval[float64, right]): [(-0.001, 7.854] < (7.854, 10.5] < (10.5, 21.679] < (21.679, 39.688] < (39.688, 512.329]]\n"
     ]
    }
   ],
   "source": [
    "# Divide all fares into quartiles\n",
    "train_data['Fare_bin'] = pd.qcut(train_data['Fare'],5)\n",
    "print(train_data['Fare_bin'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4e0562b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcut() create a new variable that idetifies the quartile range, but we can't use the string\n",
    "# so either factorize or create dummies from the result\n",
    " \n",
    "# factorize\n",
    "train_data['Fare_bin_id'] = pd.factorize(train_data['Fare_bin'])[0]\n",
    " \n",
    "# dummies\n",
    "fare_bin_dummies_df = pd.get_dummies(train_data['Fare_bin']).rename(columns=lambda x: 'Fare_' + str(x))\n",
    "train_data = pd.concat([train_data, fare_bin_dummies_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d18d8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_org = pd.read_csv('train.csv')\n",
    "test_df_org = pd.read_csv('test.csv')\n",
    "test_df_org['Survived'] = 0\n",
    "combined_train_test = train_df_org.append(test_df_org)   #891+418=1309rows, 12columns\n",
    "PassengerId = test_df_org['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9925d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Embarked'].fillna(combined_train_test['Embarked'].mode().iloc[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "11c94986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了后面的特征分析，这里我们将Embarked特征进行factorizing\n",
    "combined_train_test['Embarked'] = pd.factorize(combined_train_test['Embarked'])[0]\n",
    " \n",
    "#使用pd.get_dummies获取one-hot编码\n",
    "emb_dummies_df = pd.get_dummies(combined_train_test['Embarked'],prefix=combined_train_test[['Embarked']].columns[0])\n",
    "combined_train_test = pd.concat([combined_train_test, emb_dummies_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "52345fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Sex'] = pd.factorize(combined_train_test['Sex'])[0]\n",
    " \n",
    "sex_dummies_df = pd.get_dummies(combined_train_test['Sex'],prefix=combined_train_test[['Sex']].columns[0])\n",
    "combined_train_test = pd.concat([combined_train_test,sex_dummies_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "95180f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is each person's title?\n",
    "combined_train_test['Title'] = combined_train_test['Name'].map(lambda x: re.compile(\",(.*?)\\.\").findall(x)[0])\n",
    "combined_train_test['Title'] = combined_train_test['Title'].apply(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c0b262c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_Dict = {}\n",
    "title_Dict.update(dict.fromkeys(['Capt','Col','Major','Dr','Rev'],'Officer'))\n",
    "title_Dict.update(dict.fromkeys(['Don','Sir','the Countess','Dona','Lady'],'Royalty'))\n",
    "title_Dict.update(dict.fromkeys(['Mme','Ms','Mrs'],'Mrs'))\n",
    "title_Dict.update(dict.fromkeys(['Male','Miss'],'Miss'))\n",
    "title_Dict.update(dict.fromkeys(['Mr'],'Mr'))\n",
    "title_Dict.update(dict.fromkeys(['Master','Jonkheer'],'Master'))\n",
    " \n",
    "combined_train_test['Title'] = combined_train_test['Title'].map(title_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b0b36bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了后面的特征分析，这里我们也将Title特征进行factorizing\n",
    "combined_train_test['Title'] = pd.factorize(combined_train_test['Title'])[0]\n",
    "title_dummies_df = pd.get_dummies(combined_train_test['Title'],prefix=combined_train_test[['Title']].columns[0])\n",
    "combined_train_test = pd.concat([combined_train_test,title_dummies_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "824f4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Name_length'] = combined_train_test['Name'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "45177ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Fare'] = combined_train_test[['Fare']].fillna(combined_train_test.groupby('Pclass').transform(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a0417ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Group_Ticket'] = combined_train_test['Fare'].groupby(by=combined_train_test['Ticket']).transform('count')\n",
    "combined_train_test['Fare'] = combined_train_test['Fare']/combined_train_test['Group_Ticket']\n",
    "combined_train_test.drop(['Group_Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bed380d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Fare_bin'] = pd.qcut(combined_train_test['Fare'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0dbd8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Fare_bin'] = pd.qcut(combined_train_test['Fare'],5)\n",
    " \n",
    "combined_train_test['Fare_bin_id'] = pd.factorize(combined_train_test['Fare_bin'])[0]\n",
    " \n",
    "fare_bin_dummies_df = pd.get_dummies(combined_train_test['Fare_bin_id']).rename(columns=lambda x: 'Fare_' + str(x))\n",
    "combined_train_test = pd.concat([combined_train_test,fare_bin_dummies_df],axis=1)\n",
    "combined_train_test.drop(['Fare_bin'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "51e35b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    33.910500\n",
      "2    11.411010\n",
      "3     7.337571\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_test['Fare'].groupby(by=combined_train_test['Pclass']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6a1b55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "#建立Pclass Fare Category\n",
    "def pclass_fare_category(df,pclass1_mean_fare,pclass2_mean_fare,pclass3_mean_fare):\n",
    "    if df['Pclass'] == 1:\n",
    "        if df['Fare'] <= pclass1_mean_fare:\n",
    "            return 'Pclass1_Low'\n",
    "        else:\n",
    "            return 'Pclass1_High'\n",
    "    elif df['Pclass'] == 2:\n",
    "        if df['Fare'] <= pclass2_mean_fare:\n",
    "            return 'Pclass2_Low'\n",
    "        else:\n",
    "            return 'Pclass2_High'\n",
    "    elif df['Pclass'] == 3:\n",
    "        if df['Fare'] <= pclass3_mean_fare:\n",
    "            return 'Pclass3_Low'\n",
    "        else:\n",
    "            return 'Pclass3_High'\n",
    " \n",
    "Pclass1_mean_fare = combined_train_test['Fare'].groupby(by=combined_train_test['Pclass']).mean().get(1)\n",
    "Pclass2_mean_fare = combined_train_test['Fare'].groupby(by=combined_train_test['Pclass']).mean().get(2)\n",
    "Pclass3_mean_fare = combined_train_test['Fare'].groupby(by=combined_train_test['Pclass']).mean().get(3)\n",
    " \n",
    "#建立Pclass_Fare Category\n",
    "combined_train_test['Pclass_Fare_Category'] = combined_train_test.apply(pclass_fare_category,args=(\n",
    "        Pclass1_mean_fare,Pclass2_mean_fare,Pclass3_mean_fare),axis=1)\n",
    "pclass_level = LabelEncoder()\n",
    " \n",
    "#给每一项添加标签\n",
    "pclass_level.fit(np.array(['Pclass1_Low','Pclass1_High','Pclass2_Low','Pclass2_High','Pclass3_Low','Pclass3_High']))\n",
    " \n",
    "#转换成数值\n",
    "combined_train_test['Pclass_Fare_Category'] = pclass_level.transform(combined_train_test['Pclass_Fare_Category'])\n",
    " \n",
    "# dummy 转换\n",
    "pclass_dummies_df = pd.get_dummies(combined_train_test['Pclass_Fare_Category']).rename(columns=lambda x: 'Pclass_' + str(x))\n",
    "combined_train_test = pd.concat([combined_train_test,pclass_dummies_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "de0af763",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Pclass'] = pd.factorize(combined_train_test['Pclass'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3d0612c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_size_category(family_size):\n",
    "    if family_size <= 1:\n",
    "        return 'Single'\n",
    "    elif family_size <= 4:\n",
    "        return 'Small_Family'\n",
    "    else:\n",
    "        return 'Large_Family'\n",
    "\n",
    "combined_train_test['Family_Size'] = combined_train_test['Parch'] + combined_train_test['SibSp'] + 1\n",
    "combined_train_test['Family_Size_Category'] = combined_train_test['Family_Size'].map(family_size_category)\n",
    "\n",
    "le_family = LabelEncoder()\n",
    "le_family.fit(np.array(['Single', 'Small_Family', 'Large_Family']))\n",
    "combined_train_test['Family_Size_Category'] = le_family.transform(combined_train_test['Family_Size_Category'])\n",
    "\n",
    "family_size_dummies_df = pd.get_dummies(combined_train_test['Family_Size_Category'],\n",
    "                                        prefix=combined_train_test[['Family_Size_Category']].columns[0])\n",
    "combined_train_test = pd.concat([combined_train_test, family_size_dummies_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "aaba6afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family_Size_Category</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fare_bin_id</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Embarked  Sex  Title  Name_length  Family_Size  Family_Size_Category  \\\n",
       "5   NaN         2    0      0           16            1                     1   \n",
       "17  NaN         0    0      0           28            1                     1   \n",
       "19  NaN         1    1      1           23            1                     1   \n",
       "26  NaN         1    0      0           23            1                     1   \n",
       "28  NaN         2    1      2           29            1                     1   \n",
       "\n",
       "       Fare  Fare_bin_id  Pclass  \n",
       "5    8.4583            2       0  \n",
       "17  13.0000            3       2  \n",
       "19   7.2250            4       0  \n",
       "26   7.2250            4       0  \n",
       "28   7.8792            0       0  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_age_df = pd.DataFrame(combined_train_test[\n",
    "    ['Age', 'Embarked', 'Sex', 'Title', 'Name_length', 'Family_Size', 'Family_Size_Category','Fare', 'Fare_bin_id', 'Pclass']])\n",
    "\n",
    "missing_age_train = missing_age_df[missing_age_df['Age'].notnull()]\n",
    "missing_age_test = missing_age_df[missing_age_df['Age'].isnull()]\n",
    "\n",
    "missing_age_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "219d97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fill_missing_age(missing_age_train, missing_age_test):\n",
    "    missing_age_X_train = missing_age_train.drop(['Age'], axis=1)\n",
    "    missing_age_Y_train = missing_age_train['Age']\n",
    "    missing_age_X_test = missing_age_test.drop(['Age'], axis=1)\n",
    "\n",
    "    # model 1  gbm\n",
    "    gbm_reg = GradientBoostingRegressor(random_state=42)\n",
    "    gbm_reg_param_grid = {'n_estimators': [2000], 'max_depth': [4], 'learning_rate': [0.01], 'max_features': [3]}\n",
    "    gbm_reg_grid = model_selection.GridSearchCV(gbm_reg, gbm_reg_param_grid, cv=10, n_jobs=25, verbose=1, scoring='neg_mean_squared_error')\n",
    "    gbm_reg_grid.fit(missing_age_X_train, missing_age_Y_train)\n",
    "    print('Age feature Best GB Params:' + str(gbm_reg_grid.best_params_))\n",
    "    print('Age feature Best GB Score:' + str(gbm_reg_grid.best_score_))\n",
    "    print('GB Train Error for \"Age\" Feature Regressor:' + str(gbm_reg_grid.score(missing_age_X_train, missing_age_Y_train)))\n",
    "    missing_age_test.loc[:, 'Age_GB'] = gbm_reg_grid.predict(missing_age_X_test)\n",
    "    print(missing_age_test['Age_GB'][:4])\n",
    "\n",
    "    # model 2 rf\n",
    "    rf_reg = RandomForestRegressor()\n",
    "    rf_reg_param_grid = {'n_estimators': [200], 'max_depth': [5], 'random_state': [0]}\n",
    "    rf_reg_grid = model_selection.GridSearchCV(rf_reg, rf_reg_param_grid, cv=10, n_jobs=25, verbose=1, scoring='neg_mean_squared_error')\n",
    "    rf_reg_grid.fit(missing_age_X_train, missing_age_Y_train)\n",
    "    print('Age feature Best RF Params:' + str(rf_reg_grid.best_params_))\n",
    "    print('Age feature Best RF Score:' + str(rf_reg_grid.best_score_))\n",
    "    print('RF Train Error for \"Age\" Feature Regressor' + str(rf_reg_grid.score(missing_age_X_train, missing_age_Y_train)))\n",
    "    missing_age_test.loc[:, 'Age_RF'] = rf_reg_grid.predict(missing_age_X_test)\n",
    "    print(missing_age_test['Age_RF'][:4])\n",
    "\n",
    "    # two models merge\n",
    "    print('shape1', missing_age_test['Age'].shape, missing_age_test[['Age_GB', 'Age_RF']].mode(axis=1).shape)\n",
    "    # missing_age_test['Age'] = missing_age_test[['Age_GB', 'Age_LR']].mode(axis=1)\n",
    "\n",
    "    missing_age_test.loc[:, 'Age'] = np.mean([missing_age_test['Age_GB'], missing_age_test['Age_RF']])\n",
    "    print(missing_age_test['Age'][:4])\n",
    "\n",
    "    missing_age_test.drop(['Age_GB', 'Age_RF'], axis=1, inplace=True)\n",
    "\n",
    "    return missing_age_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e18e2840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Age feature Best GB Params:{'learning_rate': 0.01, 'max_depth': 4, 'max_features': 3, 'n_estimators': 2000}\n",
      "Age feature Best GB Score:-128.38286366239385\n",
      "GB Train Error for \"Age\" Feature Regressor:-65.2562037120689\n",
      "5     37.508266\n",
      "17    31.580052\n",
      "19    34.597808\n",
      "26    29.076996\n",
      "Name: Age_GB, dtype: float64\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Age feature Best RF Params:{'max_depth': 5, 'n_estimators': 200, 'random_state': 0}\n",
      "Age feature Best RF Score:-119.64194051962507\n",
      "RF Train Error for \"Age\" Feature Regressor-96.82296812792812\n",
      "5     33.513123\n",
      "17    33.098071\n",
      "19    34.853983\n",
      "26    28.148613\n",
      "Name: Age_RF, dtype: float64\n",
      "shape1 (263,) (263, 2)\n",
      "5     29.97686\n",
      "17    29.97686\n",
      "19    29.97686\n",
      "26    29.97686\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "combined_train_test.loc[(combined_train_test.Age.isnull()), 'Age'] = fill_missing_age(missing_age_train, missing_age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bad41808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family_Size_Category</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fare_bin_id</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.97686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29.97686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.97686</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29.97686</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.97686</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  Embarked  Sex  Title  Name_length  Family_Size  \\\n",
       "5   29.97686         2    0      0           16            1   \n",
       "17  29.97686         0    0      0           28            1   \n",
       "19  29.97686         1    1      1           23            1   \n",
       "26  29.97686         1    0      0           23            1   \n",
       "28  29.97686         2    1      2           29            1   \n",
       "\n",
       "    Family_Size_Category     Fare  Fare_bin_id  Pclass  \n",
       "5                      1   8.4583            2       0  \n",
       "17                     1  13.0000            3       2  \n",
       "19                     1   7.2250            4       0  \n",
       "26                     1   7.2250            4       0  \n",
       "28                     1   7.8792            0       0  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_age_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c8cda83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test['Ticket_Letter'] = combined_train_test['Ticket'].str.split().str[0]\n",
    "combined_train_test['Ticket_Letter'] = combined_train_test['Ticket_Letter'].apply(lambda x: 'U0' if x.isnumeric() else x)\n",
    "\n",
    "# 如果要提取数字信息，则也可以这样做，现在我们对数字票单纯地分为一类。\n",
    "# combined_train_test['Ticket_Number'] = combined_train_test['Ticket'].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "# combined_train_test['Ticket_Number'].fillna(0, inplace=True)\n",
    "\n",
    "# 将 Ticket_Letter factorize\n",
    "combined_train_test['Ticket_Letter'] = pd.factorize(combined_train_test['Ticket_Letter'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "571b682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_test.loc[combined_train_test.Cabin.isnull(), 'Cabin'] = 'U0'\n",
    "combined_train_test['Cabin'] = combined_train_test['Cabin'].apply(lambda x: 0 if x == 'U0' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8b70cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scale_age_fare = preprocessing.StandardScaler().fit(combined_train_test[['Age','Fare','Name_length']])\n",
    "combined_train_test[['Age','Fare','Name_length']] = scale_age_fare.transform(combined_train_test[['Age','Fare','Name_length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d73e0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_backup = combined_train_test\n",
    "\n",
    "combined_train_test.drop(['PassengerId','Embarked','Sex','Name','Fare_bin_id','Pclass_Fare_Category',                          'Parch','SibSp','Family_Size_Category','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fc0296cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = combined_train_test[:891]\n",
    "test_data = combined_train_test[891:]\n",
    " \n",
    "titanic_train_data_X = train_data.drop(['Survived'],axis=1)\n",
    "titanic_train_data_Y = train_data['Survived']\n",
    "titanic_test_data_X = test_data.drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "da4cb253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 34)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "41c7b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "def get_top_n_features(titanic_train_data_X,titanic_train_data_Y,top_n_features):\n",
    "    \n",
    "    #randomforest\n",
    "    rf_est = RandomForestClassifier(random_state=0)\n",
    "    rf_param_grid = {'n_estimators':[500],'min_samples_split':[2,3],'max_depth':[20]}\n",
    "    rf_grid = model_selection.GridSearchCV(rf_est,rf_param_grid,n_jobs=25,cv=10,verbose=1)\n",
    "    rf_grid.fit(titanic_train_data_X,titanic_train_data_Y)\n",
    "    print('Top N Features Best RF Params:' + str(rf_grid.best_params_))\n",
    "    print('Top N Features Best RF Score:' + str(rf_grid.best_score_))\n",
    "    print('Top N Features RF Train Score:' + str(rf_grid.score(titanic_train_data_X,titanic_train_data_Y)))\n",
    "    feature_imp_sorted_rf = pd.DataFrame({'feature':list(titanic_train_data_X),\n",
    "                                          'importance':rf_grid.best_estimator_.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    features_top_n_rf = feature_imp_sorted_rf.head(top_n_features)['feature']\n",
    "    print('Sample 10 Feeatures from RF Classifier')\n",
    "    print(str(features_top_n_rf[:10]))\n",
    "    \n",
    "    #AdaBoost\n",
    "    ada_est = AdaBoostClassifier(random_state=0)\n",
    "    ada_param_grid = {'n_estimators':[500],'learning_rate':[0.01,0.1]}\n",
    "    ada_grid = model_selection.GridSearchCV(ada_est,ada_param_grid,n_jobs=25,cv=10,verbose=1)\n",
    "    ada_grid.fit(titanic_train_data_X,titanic_train_data_Y)\n",
    "    print('Top N Features Best Ada Params:' + str(ada_grid.best_params_))\n",
    "    print('Top N Features Best Ada Score:' + str(ada_grid.best_score_))\n",
    "    print('Top N Features Ada Train Score:' + str(ada_grid.score(titanic_train_data_X,titanic_train_data_Y)))\n",
    "    feature_imp_sorted_ada = pd.DataFrame({'feature':list(titanic_train_data_X),\n",
    "                                           'importance':ada_grid.best_estimator_.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    features_top_n_ada = feature_imp_sorted_ada.head(top_n_features)['feature']\n",
    "    print('Sample 10 Features from Ada Classifier:')\n",
    "    print(str(features_top_n_ada[:10]))\n",
    "    \n",
    "    #ExtraTree\n",
    "    et_est = ExtraTreesClassifier(random_state=0)\n",
    "    et_param_grid = {'n_estimators':[500],'min_samples_split':[3,4],'max_depth':[20]}\n",
    "    et_grid = model_selection.GridSearchCV(et_est,et_param_grid,n_jobs=25,cv=10,verbose=1)\n",
    "    et_grid.fit(titanic_train_data_X,titanic_train_data_Y)\n",
    "    print('Top N Features Best ET Params:' + str(et_grid.best_params_))\n",
    "    print('Top N Features Best DT Score:' + str(et_grid.best_score_))\n",
    "    print('Top N Features ET Train Score:' + str(et_grid.score(titanic_train_data_X,titanic_train_data_Y)))\n",
    "    feature_imp_sorted_et = pd.DataFrame({'feature':list(titanic_train_data_X),\n",
    "                                          'importance':et_grid.best_estimator_.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    features_top_n_et = feature_imp_sorted_et.head(top_n_features)['feature']\n",
    "    print('Sample 10 Features from ET Classifier:')\n",
    "    print(str(features_top_n_et[:10]))\n",
    "    \n",
    "    # GradientBoosting\n",
    "    gb_est = GradientBoostingClassifier(random_state=0)\n",
    "    gb_param_grid = {'n_estimators':[500],'learning_rate':[0.01,0.1],'max_depth':[20]}\n",
    "    gb_grid = model_selection.GridSearchCV(gb_est,gb_param_grid,n_jobs=25,cv=10,verbose=1)\n",
    "    gb_grid.fit(titanic_train_data_X,titanic_train_data_Y)\n",
    "    print('Top N Features Best GB Params:' + str(gb_grid.best_params_))\n",
    "    print('Top N Features Best GB Score:' + str(gb_grid.best_score_))\n",
    "    print('Top N Features GB Train Score:' + str(gb_grid.score(titanic_train_data_X,titanic_train_data_Y)))\n",
    "    feature_imp_sorted_gb = pd.DataFrame({'feature':list(titanic_train_data_X),\n",
    "                                          'importance':gb_grid.best_estimator_.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    features_top_n_gb = feature_imp_sorted_gb.head(top_n_features)['feature']\n",
    "    print('Sample 10 Feature from GB Classifier:')\n",
    "    print(str(features_top_n_gb[:10]))\n",
    "    \n",
    "    # DecisionTree\n",
    "    dt_est = DecisionTreeClassifier(random_state=0)\n",
    "    dt_param_grid = {'min_samples_split':[2,4],'max_depth':[20]}\n",
    "    dt_grid = model_selection.GridSearchCV(dt_est,dt_param_grid,n_jobs=25,cv=10,verbose=1)\n",
    "    dt_grid.fit(titanic_train_data_X,titanic_train_data_Y)\n",
    "    print('Top N Features Bset DT Params:' + str(dt_grid.best_params_))\n",
    "    print('Top N Features Best DT Score:' + str(dt_grid.best_score_))\n",
    "    print('Top N Features DT Train Score:' + str(dt_grid.score(titanic_train_data_X,titanic_train_data_Y)))\n",
    "    feature_imp_sorted_dt = pd.DataFrame({'feature':list(titanic_train_data_X),\n",
    "                                          'importance':dt_grid.best_estimator_.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    features_top_n_dt = feature_imp_sorted_dt.head(top_n_features)['feature']\n",
    "    print('Sample 10 Features from DT Classifier:')\n",
    "    print(str(features_top_n_dt[:10]))\n",
    "    \n",
    "    # merge the three models\n",
    "    features_top_n = pd.concat([features_top_n_rf,features_top_n_ada,features_top_n_et,features_top_n_gb,features_top_n_dt],\n",
    "                              ignore_index=True).drop_duplicates()\n",
    "    features_importance = pd.concat([feature_imp_sorted_rf,feature_imp_sorted_ada,feature_imp_sorted_et,\n",
    "                                     feature_imp_sorted_gb,feature_imp_sorted_dt],ignore_index=True)\n",
    "    \n",
    "    return features_top_n,features_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f735a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "Top N Features Best RF Params:{'max_depth': 20, 'min_samples_split': 3, 'n_estimators': 500}\n",
      "Top N Features Best RF Score:0.8271785268414481\n",
      "Top N Features RF Train Score:0.9764309764309764\n",
      "Sample 10 Feeatures from RF Classifier\n",
      "1               Age\n",
      "17      Name_length\n",
      "2              Fare\n",
      "8             Sex_1\n",
      "9             Title\n",
      "11          Title_0\n",
      "7             Sex_0\n",
      "29      Family_Size\n",
      "0            Pclass\n",
      "33    Ticket_Letter\n",
      "Name: feature, dtype: object\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "Top N Features Best Ada Params:{'learning_rate': 0.01, 'n_estimators': 500}\n",
      "Top N Features Best Ada Score:0.8181897627965042\n",
      "Top N Features Ada Train Score:0.8204264870931538\n",
      "Sample 10 Features from Ada Classifier:\n",
      "11                   Title_0\n",
      "2                       Fare\n",
      "30    Family_Size_Category_0\n",
      "29               Family_Size\n",
      "7                      Sex_0\n",
      "0                     Pclass\n",
      "3                      Cabin\n",
      "8                      Sex_1\n",
      "17               Name_length\n",
      "1                        Age\n",
      "Name: feature, dtype: object\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "Top N Features Best ET Params:{'max_depth': 20, 'min_samples_split': 4, 'n_estimators': 500}\n",
      "Top N Features Best DT Score:0.8237952559300874\n",
      "Top N Features ET Train Score:0.9708193041526375\n",
      "Sample 10 Features from ET Classifier:\n",
      "11          Title_0\n",
      "7             Sex_0\n",
      "8             Sex_1\n",
      "17      Name_length\n",
      "1               Age\n",
      "2              Fare\n",
      "3             Cabin\n",
      "9             Title\n",
      "33    Ticket_Letter\n",
      "13          Title_2\n",
      "Name: feature, dtype: object\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "Top N Features Best GB Params:{'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 500}\n",
      "Top N Features Best GB Score:0.7835205992509363\n",
      "Top N Features GB Train Score:0.9966329966329966\n",
      "Sample 10 Feature from GB Classifier:\n",
      "11                   Title_0\n",
      "1                        Age\n",
      "2                       Fare\n",
      "17               Name_length\n",
      "30    Family_Size_Category_0\n",
      "29               Family_Size\n",
      "28                  Pclass_5\n",
      "9                      Title\n",
      "0                     Pclass\n",
      "33             Ticket_Letter\n",
      "Name: feature, dtype: object\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "Top N Features Bset DT Params:{'max_depth': 20, 'min_samples_split': 4}\n",
      "Top N Features Best DT Score:0.7823220973782771\n",
      "Top N Features DT Train Score:0.9607182940516273\n",
      "Sample 10 Features from DT Classifier:\n",
      "11                   Title_0\n",
      "1                        Age\n",
      "2                       Fare\n",
      "17               Name_length\n",
      "30    Family_Size_Category_0\n",
      "16                   Title_5\n",
      "28                  Pclass_5\n",
      "0                     Pclass\n",
      "33             Ticket_Letter\n",
      "29               Family_Size\n",
      "Name: feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "feature_to_pick = 30\n",
    "feature_top_n,feature_importance = get_top_n_features(titanic_train_data_X,titanic_train_data_Y,feature_to_pick)\n",
    "titanic_train_data_X = pd.DataFrame(titanic_train_data_X[feature_top_n])\n",
    "titanic_test_data_X = pd.DataFrame(titanic_test_data_X[feature_top_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "799014ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    " \n",
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = titanic_train_data_X.shape[0]\n",
    "ntest = titanic_test_data_X.shape[0]\n",
    "SEED = 0 #for reproducibility\n",
    "NFOLDS = 7 # set folds for out-of-fold prediction\n",
    "kf = KFold(n_splits = NFOLDS,random_state=SEED,shuffle= True)\n",
    " \n",
    "def get_out_fold(clf,x_train,y_train,x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS,ntest))\n",
    "    \n",
    "    for i, (train_index,test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        clf.fit(x_tr,y_tr)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i,:] = clf.predict(x_test)\n",
    "        \n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1,1),oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "113c07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "rf = RandomForestClassifier(n_estimators=500,warm_start=True,max_features='sqrt',max_depth=6,min_samples_split=3,min_samples_leaf=2,n_jobs=-1,verbose=0)\n",
    " \n",
    "ada = AdaBoostClassifier(n_estimators=500,learning_rate=0.1)\n",
    " \n",
    "et = ExtraTreesClassifier(n_estimators=500,n_jobs=-1,max_depth=8,min_samples_leaf=2,verbose=0)\n",
    " \n",
    "gb = GradientBoostingClassifier(n_estimators=500,learning_rate=0.008,min_samples_split=3,min_samples_leaf=2,max_depth=5,verbose=0)\n",
    " \n",
    "dt = DecisionTreeClassifier(max_depth=8)\n",
    " \n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    " \n",
    "svm = SVC(kernel='linear',C=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8db610d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train,test and target(Survived) dataframes to feed into our models\n",
    "x_train = titanic_train_data_X.values   #Creates an array of the train data\n",
    "x_test = titanic_test_data_X.values   #Creates an array of the test data\n",
    "y_train = titanic_train_data_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c3975a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions.These base result will be used as new featurs\n",
    "rf_oof_train,rf_oof_test = get_out_fold(rf,x_train,y_train,x_test)  # Random Forest\n",
    "ada_oof_train,ada_oof_test = get_out_fold(ada,x_train,y_train,x_test)  # AdaBoost\n",
    "et_oof_train,et_oof_test = get_out_fold(et,x_train,y_train,x_test)  # Extra Trees\n",
    "gb_oof_train,gb_oof_test = get_out_fold(gb,x_train,y_train,x_test)  # Gradient Boost\n",
    "dt_oof_train,dt_oof_test = get_out_fold(dt,x_train,y_train,x_test)  #Decision Tree\n",
    "knn_oof_train,knn_oof_test = get_out_fold(knn,x_train,y_train,x_test)  # KNeighbors\n",
    "svm_oof_train,svm_oof_test = get_out_fold(svm,x_train,y_train,x_test)  # Support Vector\n",
    " \n",
    "print(\"Training is complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b1ce68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((rf_oof_train,ada_oof_train,et_oof_train,gb_oof_train,dt_oof_train,knn_oof_train,svm_oof_train),axis=1)\n",
    "x_test =np.concatenate((rf_oof_test,ada_oof_test,et_oof_test,gb_oof_test,dt_oof_test,knn_oof_test,svm_oof_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e2b2c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.0-py3-none-win_amd64.whl (126.1 MB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5320b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    " \n",
    "gbm = XGBClassifier(n_estimators=200,max_depth=4,min_child_weight=2,gamma=0.9,subsample=0.8,\n",
    "                    colsample_bytree=0.8,objective='binary:logistic',nthread=-1,scale_pos_weight=1).fit(x_train,y_train)\n",
    "predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e1299dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "StackingSubmission = pd.DataFrame({'PassengerId':PassengerId,'Survived':predictions})\n",
    "StackingSubmission.to_csv('StackingSubmission.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "74b12485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 C 中的卷是 Windows-SSD\n",
      " 卷的序列号是 CC90-FE43\n",
      "\n",
      " C:\\Users\\Lenovo\\Desktop\\Titanic 的目录\n",
      "\n",
      "2022/04/19  10:01    <DIR>          .\n",
      "2022/04/19  10:01    <DIR>          ..\n",
      "2022/04/14  11:10    <DIR>          .idea\n",
      "2022/04/19  09:42    <DIR>          .ipynb_checkpoints\n",
      "2019/12/11  02:17             3,258 gender_submission.csv\n",
      "2022/04/19  09:36             3,258 prdict_test.csv\n",
      "2022/04/19  10:01             3,258 StackingSubmission.csv\n",
      "2019/12/11  02:17            28,629 test.csv\n",
      "2022/04/19  09:36           260,019 Titanic.ipynb\n",
      "2019/12/11  02:17            61,194 train.csv\n",
      "2022/04/19  00:38           238,064 Untitled.ipynb\n",
      "2022/04/19  09:58            58,107 Untitled1.ipynb\n",
      "               8 个文件        655,787 字节\n",
      "               4 个目录  3,707,465,728 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4736c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
